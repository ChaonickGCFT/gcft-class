- name: Build & run CLASS
  working-directory: class_public
  run: |
    make -j"$(nproc)"

    echo "🧪 Running CLASS with z_pk='0,25'..."
    ./class ../gcft.ini z_pk='0,25' root='gcft00' || { echo '❌ CLASS run failed'; exit 1; }

    echo "🔍 Checking for CLASS outputs:"
    ls -lh gcft00_*.dat || { echo '❌ CLASS output files missing'; exit 1; }

    mkdir -p "$GITHUB_WORKSPACE/output"
    cp gcft00_*_background.dat gcft00_*_thermodynamics.dat gcft00_*_cl.dat gcft00_*_pk.dat "$GITHUB_WORKSPACE/output/"

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  reproduce:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Init Git LFS (for any .dat tracked via LFS)
        run: |
          git lfs install
          git lfs pull || true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: System deps
        run: sudo apt-get update && sudo apt-get install -y build-essential gfortran

      - name: Python deps
        if: hashFiles('requirements.txt') != ''
        run: pip install -r requirements.txt

      - name: Fetch CLASS
        run: git clone --depth 1 https://github.com/lesgourg/class_public.git class_public

      - name: Copy GCFT files into CLASS dir
        run: |
          cp gcft.ini gcft_class_background.dat class_public/

      - name: Build & run CLASS
        working-directory: class_public
        run: |
          make -j"$(nproc)"
          ./class ../gcft.ini z_pk='0,25' root='gcft00'
          mkdir -p "$GITHUB_WORKSPACE/output"
          cp gcft00_*.dat "$GITHUB_WORKSPACE/output/" || true

      - name: List outputs
        run: ls -lh output || true

      - name: Write verify script
        run: |
          cat > verify.py <<'PY'
          import sys, re, numpy as np, pathlib as P

          pairs = [
            ("output/gcft00_pk.dat","gcft00_pk.dat"),
            ("output/gcft00_cl.dat","gcft00_cl.dat"),
            ("output/gcft00_background.dat","gcft00_background.dat"),
            ("output/gcft00_thermodynamics.dat","gcft00_thermodynamics.dat"),
          ]

          num = re.compile(r'^[+-]?(?:\d+(?:\.\d*)?|\.\d+)(?:[eE][+-]?\d+)?$')
          def load(path):
              rows=[]
              for ln in open(path,'r',errors='ignore'):
                  s=ln.strip()
                  if not s or s.startswith('#'):
                      continue
                  toks=[t for t in re.split(r'\s+', s) if num.match(t)]
                  if not toks:
                      continue
                  rows.append([float(t) for t in toks])
              return np.array(rows,float)

          def read_pk_blocks(path):
              blocks = {}
              z = None
              k, pk = [], []
              with open(path, "r", errors="ignore") as f:
                  for line in f:
                      s = line.strip()
                      if not s:
                          continue
                      if s.startswith("#") and "z =" in s:
                          if z is not None and k:
                              blocks[z] = (np.array(k), np.array(pk))
                              k, pk = [], []
                          try:
                              z = float(s.split("z =",1)[1].split()[0].replace(",",""))
                          except:
                              z = None
                          continue
                      if not s.startswith("#"):
                          cols = s.split()
                          if len(cols) >= 2:
                              k.append(float(cols[0])); pk.append(float(cols[1]))
              if z is not None and k:
                  blocks[z] = (np.array(k), np.array(pk))
              return blocks

          def max_rel(a,b):
              return float(np.nanmax(np.abs(a-b)/np.maximum(np.abs(b),1e-12)))

          ok=True
          tol = 5e-6

          for new, ref in pairs:
              pn, pr = P.Path(new), P.Path(ref)
              if not pn.exists():
                  print(f"[FAIL] missing {new}"); ok=False; continue
              if not pr.exists():
                  print(f"[WARN] no baseline {ref} (skipping)"); continue

              if new.endswith("_pk.dat"):
                  Ablocks = read_pk_blocks(pn)
                  Bblocks = read_pk_blocks(pr)

                  if 25.0 not in Ablocks:
                      print(f"[FAIL] {new} missing z=25 block"); ok=False

                  common = sorted(set(Ablocks) & set(Bblocks))
                  if not common:
                      print(f"[FAIL] no common z-blocks for {new}"); ok=False; continue

                  for z in common:
                      kA, PA = Ablocks[z]; kB, PB = Bblocks[z]
                      kmin, kmax = max(kA.min(), kB.min()), min(kA.max(), kB.max())
                      m = (kB>=kmin) & (kB<=kmax)
                      if not np.any(m):
                          print(f"[FAIL] no overlap in k-range for {new} @ z={z}"); ok=False; continue
                      PAi = np.interp(kB[m], kA, PA)
                      diff = max_rel(PAi, PB[m])
                      print(f"[{'OK' if diff<=tol else 'FAIL'}] {new} @ z={z} max rel diff={diff:.3e}")
                      if diff>tol: ok=False

              else:
                  A, B = load(pn), load(pr)
                  if A.shape != B.shape:
                      print(f"[FAIL] shape {A.shape}!={B.shape} for {new}"); ok=False
                  else:
                      diff = max_rel(A, B)
                      print(f"[{'OK' if diff<=tol else 'FAIL'}] {new} max rel diff={diff:.3e}")
                      if diff>tol: ok=False

          sys.exit(0 if ok else 1)
          PY

      - name: Verify outputs vs baselines
        run: python verify.py

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gcft-outputs
          path: |
            output/gcft00_*.dat
